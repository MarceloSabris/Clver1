{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b7f8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "print('fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fbbe35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9388c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GravarArquivo ( data_dict,fname):\n",
    "    fname = fname +\"_\" +str(len(data_dict)) + '.json'\n",
    "    print(\"gravar arquivo: \" + fname + \" qtd: \" +  str(len(data_dict)))\n",
    "    os.makedirs('Percentage_'+ str(percentageData) , exist_ok=True)\n",
    "    fname = 'Percentage_'+ str(percentageData) + \"/\" + fname\n",
    "    # Create file\n",
    "    with open(fname, 'w') as outfile:\n",
    "        json.dump(data_dict, outfile, ensure_ascii=False, indent=4) \n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d92e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "            plt.plot(history.history['loss'], label='training loss')\n",
    "            plt.plot(history.history['val_loss'], label=' validation loss')\n",
    "            #plt.ylim([0, 10])\n",
    "            plt.xlabel('Epopch')\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig( 'Percentage_'+ str(percentageData) + '/error_datalenght.png')\n",
    "            plt.show()\n",
    "\n",
    "def plot_acc(history):  \n",
    "            plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "            plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "            plt.title('model accuracy')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.savefig('Percentage_'+ str(percentageData) + '/accuracy_datalenght.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8074a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs : 0\n",
      "Tensorflow GPU : True\n"
     ]
    }
   ],
   "source": [
    "#Check GPU is available for training or not Or whether the tensorflow version can utilize gpu \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Number of GPUs :\", len(physical_devices)) \n",
    "print(\"Tensorflow GPU :\",tf.test.is_built_with_cuda())\n",
    "if len(physical_devices)>0:\n",
    "    device=\"/GPU:0\"\n",
    "else:\n",
    "    device=\"/CPU:0\"\n",
    "percentageData = 'fulll_material'\n",
    "posTrainList=[]\n",
    "posValList=[]\n",
    "BATCH_SIZE=50\n",
    "IMG_SIZE=(200,200)\n",
    "QtdEpocasGravarCHKP = 2\n",
    "Epochs = 50\n",
    "lenghtDataTrain = 0\n",
    "lenghtDataVal =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a76710c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n",
      "fim\n"
     ]
    }
   ],
   "source": [
    "trainList=[]\n",
    "\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_train_questions.json') as f:\n",
    "    print('oi')\n",
    "    data = json.load(f)\n",
    "    with open('/home/jupyter/input/train_questao_material.json') as mat: \n",
    "     mat1 = json.load(mat)\n",
    "     for m in mat1:\n",
    "        K=int(str(m).split(':')[1].replace('''''','').replace('}',''))\n",
    "        i = data['questions'][K]\n",
    "       \n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/train/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "           \n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        trainList.append(temp)\n",
    "        posTrainList.append(K)\n",
    "f.close()\n",
    "labels=['Path','Question','Answer']\n",
    "train_dataframe = pd.DataFrame.from_records(trainList, columns=labels)#training Dataframe \n",
    "del(data)\n",
    "del(trainList)\n",
    "print('fim')\n",
    "lenghtDataTrain = len(posTrainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f18148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passou carregou\n"
     ]
    }
   ],
   "source": [
    "valList=[]\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_val_questions.json') as f:\n",
    "    data = json.load(f)\n",
    "    with open('/home/jupyter/input/val_questao_material.json') as mat: \n",
    "     mat1 = json.load(mat)\n",
    "     for m in mat1:\n",
    "        K=int(str(m).split(':')[1].replace('''''','').replace('}',''))\n",
    "            \n",
    "        i = data['questions'][K]\n",
    "        \n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/val/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        valList.append(temp)\n",
    "        posValList.append(K)\n",
    "f.close() \n",
    "\n",
    "val_dataframe = pd.DataFrame.from_records(valList, columns=labels)#validation Dataframe\n",
    "del(data)\n",
    "del(valList)\n",
    "val_dataframe.head()\n",
    "print('passou carregou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ca5cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Encoder with sample questions - \n",
      " \n",
      "Original Text = What is the material of the small thing to the left of the small purple block in front of the small cyan rubber cube?\n",
      "After Encoding = [8, 12, 20, 45, 85, 20, 93, 16, 44, 20, 29, 85, 20, 93, 59, 97, 40, 42, 85, 20, 93, 96, 24, 55]\n"
     ]
    }
   ],
   "source": [
    "vocab_set=set()#set object used to store the vocabulary\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "for i in val_dataframe['Question']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in train_dataframe['Question']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in val_dataframe['Answer']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in train_dataframe['Answer']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "    \n",
    "vocab_set.update('12aaaa')\n",
    "vocab_set.update('1234sssa')\n",
    "\n",
    "#\n",
    "#Creating an Encoder and a Function to preprocess the text data during the training and inference    \n",
    "    \n",
    "encoder=tfds.features.text.TokenTextEncoder(vocab_set)\n",
    "index=2\n",
    "print(\"Testing the Encoder with sample questions - \\n \")\n",
    "example_text=encoder.encode(train_dataframe['Question'][index])\n",
    "print(\"Original Text = \"+train_dataframe['Question'][index])\n",
    "print(\"After Encoding = \"+str(example_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d54309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gravar arquivo: Val_pos_13520.json qtd: 13520\n",
      "gravar arquivo: Train_pos_62830.json qtd: 62830\n",
      "gravar arquivo: Vocab_set_99.json qtd: 99\n"
     ]
    }
   ],
   "source": [
    "GravarArquivo(posValList,'Val_pos' )\n",
    "GravarArquivo(posTrainList,'Train_pos' )\n",
    "GravarArquivo(list(vocab_set), 'Vocab_set' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f520a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"EagerPyFunc_1:0\", shape=(1,), dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "Tensor(\"EagerPyFunc_1:0\", shape=(1,), dtype=int32, device=/job:localhost/replica:0/task:0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Function that uses the encoder created to encode the input question and answer string\n",
    "def encode_fn(text):\n",
    "    return np.array(encoder.encode(text.numpy()))\n",
    "\n",
    "\n",
    "#Function to load and decode the image from the file paths in the dataframe and use the encoder function\n",
    "def preprocess(ip,ans):\n",
    "    img,ques=ip#ip is a list containing image paths and questions\n",
    "    img=tf.io.read_file(img)\n",
    "    img=tf.image.decode_jpeg(img,channels=3)\n",
    "    # quantos canais de cores tem \n",
    "    img=tf.image.resize(img,IMG_SIZE)\n",
    "    img=tf.math.divide(img, 255)# \n",
    "    #The question string is converted to encoded list with fixed size of 50 with padding with 0 value\n",
    "    ques=tf.py_function(encode_fn,inp=[ques],Tout=tf.int32)\n",
    "    paddings = [[0, 50-tf.shape(ques)[0]]]\n",
    "    ques = tf.pad(ques, paddings, 'CONSTANT', constant_values=0)\n",
    "    ques.set_shape([50])#Explicit shape must be defined in order to create the Input pipeline\n",
    "    \n",
    "    #The Answer is also encoded \n",
    "    ans=tf.py_function(encode_fn,inp=[ans],Tout=tf.int32)\n",
    "    ans.set_shape([1])\n",
    "    print(ans)\n",
    "    return (img,ques),ans\n",
    "    \n",
    "def create_pipeline(dataframe):\n",
    "    raw_df=tf.data.Dataset.from_tensor_slices(((dataframe['Path'],dataframe['Question']),dataframe['Answer']))\n",
    "    df=raw_df.map(preprocess)#Preprocessing function is applied to the dataset\n",
    "    df=df.batch(BATCH_SIZE)#The dataset is batched\n",
    "    return df\n",
    "\n",
    "#The training and validation Dataset objects are created\n",
    "train_dataset=create_pipeline(train_dataframe)\n",
    "validation_dataset=create_pipeline(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b1a31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 256)      25600       text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "image_input (InputLayer)        [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 50, 512)      1050624     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functiona (None, 7, 7, 1280)   2257984     image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 50, 512)      1574912     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           mobilenetv2_1.00_224[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1024)         4198400     bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2304)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 100)          230500      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,338,020\n",
      "Trainable params: 9,303,908\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating the CNN model for image processing\n",
    "\n",
    "\n",
    "CNN_Input=tf.keras.layers.Input(shape=(200,200,3),name='image_input')\n",
    "\n",
    "mobilenetv2=tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(200,200,3), alpha=1.0, include_top=False,\n",
    "                                                      weights='imagenet', input_tensor=CNN_Input)\n",
    "\n",
    "CNN_model=tf.keras.models.Sequential()\n",
    "CNN_model.add(CNN_Input)\n",
    "CNN_model.add(mobilenetv2)\n",
    "CNN_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "\n",
    "#Creating the RNN model for text processing\n",
    "RNN_model=tf.keras.models.Sequential()\n",
    "\n",
    "RNN_Input=tf.keras.layers.Input(shape=(50),name='text_input')\n",
    "RNN_model.add(RNN_Input)\n",
    "RNN_model.add(tf.keras.layers.Embedding (len(vocab_set)+1,256))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512,return_sequences=False,recurrent_initializer='glorot_uniform')))\n",
    "\n",
    "\n",
    "concat=tf.keras.layers.concatenate([CNN_model.output,RNN_model.output])\n",
    "dense_out=tf.keras.layers.Dense(len(vocab_set)+1,activation='softmax',name='output')(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[CNN_Input,RNN_Input],\n",
    "                    outputs=dense_out)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9051370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125660\n",
      "Epoch 1/50\n",
      " 500/1257 [==========>...................] - ETA: 38:18 - loss: 0.8221 - sparse_categorical_accuracy: 0.5457\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      " 708/1257 [===============>..............] - ETA: 27:49 - loss: 0.7858 - sparse_categorical_accuracy: 0.5546\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      " 868/1257 [===================>..........] - ETA: 19:43 - loss: 0.7681 - sparse_categorical_accuracy: 0.5591\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      "1003/1257 [======================>.......] - ETA: 12:53 - loss: 0.7568 - sparse_categorical_accuracy: 0.5622\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      "1122/1257 [=========================>....] - ETA: 6:51 - loss: 0.7488 - sparse_categorical_accuracy: 0.5644\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      "1229/1257 [============================>.] - ETA: 1:25 - loss: 0.7427 - sparse_categorical_accuracy: 0.5662\n",
      "Epoch 00001: saving model to Percentage_fulll_material/weights-001.ckpt\n",
      "1257/1257 [==============================] - 4022s 3s/step - loss: 0.7412 - sparse_categorical_accuracy: 0.5667 - val_loss: 21.9854 - val_sparse_categorical_accuracy: 0.0527\n",
      "Epoch 2/50\n",
      " 155/1257 [==>...........................] - ETA: 55:37 - loss: 0.6433 - sparse_categorical_accuracy: 0.6078"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scheduler(epoch):\n",
    "  if epoch < 1:\n",
    "    return 0.001\n",
    "  else:\n",
    "    return 0.001 * tf.math.exp(0.1 * (1 - epoch))\n",
    "\n",
    "checkpoint_path = 'Percentage_'+ str(percentageData) + '/weights-{epoch:03d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=QtdEpocasGravarCHKP*lenghtDataTrain)\n",
    "\n",
    "print(QtdEpocasGravarCHKP*lenghtDataTrain)\n",
    "\n",
    "LRS = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "csv_callback=tf.keras.callbacks.CSVLogger(\n",
    "   'Percentage_'+ str(percentageData) + '/'+ \"Training Parameters.csv\",\n",
    "    separator=',', append=False\n",
    ")\n",
    "\n",
    "\n",
    "with tf.device(device) :\n",
    "    history =  model.fit(train_dataset,\n",
    "              validation_data=validation_dataset,\n",
    "              callbacks=[csv_callback,cp_callback,cp_callback],\n",
    "              epochs=Epochs)\n",
    "\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "history.history\n",
    "hist.tail()\n",
    "plot_loss(history)\n",
    "plot_acc(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443db335",
   "metadata": {},
   "outputs": [],
   "source": [
    "contadorCerto =0\n",
    "contadorErro =0 \n",
    "\n",
    "for contador in range(lenghtDataTrain) :\n",
    "   \n",
    "    im=cv2.imread(train_dataframe.iloc[contador]['Path'])\n",
    "    im=cv2.resize(im,(200,200))\n",
    "    q=train_dataframe.iloc[contador]['Question'] \n",
    "    q=encoder.encode(q)\n",
    "    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "    q=np.array(q)\n",
    "    im.resize(1,200,200,3)\n",
    "    q.resize(1,50)\n",
    "    ans=model.predict([im,q]) \n",
    "    decodAns = encoder.decode([np.argmax(ans)])\n",
    "    if train_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "        contadorErro = contadorErro +1\n",
    "    else:     \n",
    "        contadorCerto = contadorCerto +1\n",
    "      \n",
    "print(contadorCerto)\n",
    "print(contadorErro)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "VerifTrainList=[]\n",
    "VerifTrainList.append(\"Acerto - \" + contadorCerto )\n",
    "VerifTrainList.append(\"Erro - \" + contadorErro )\n",
    "GravarArquivo(VerifTrainList,'Verif_TrainList' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "contadorCerto =0\n",
    "contadorErro =0 \n",
    "\n",
    "for contador in range(lenghtDataVal) :\n",
    "   \n",
    "    im=cv2.imread(val_dataframe.iloc[contador]['Path'])\n",
    "    im=cv2.resize(im,(200,200))\n",
    "    q=val_dataframe.iloc[contador]['Question'] \n",
    "    q=encoder.encode(q)\n",
    "    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "    q=np.array(q)\n",
    "    im.resize(1,200,200,3)\n",
    "    q.resize(1,50)\n",
    "    ans=model.predict([im,q]) \n",
    "    decodAns = encoder.decode([np.argmax(ans)])\n",
    "    if val_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "        contadorErro = contadorErro +1\n",
    "    else:     \n",
    "        contadorCerto = contadorCerto +1\n",
    "      \n",
    "print(contadorCerto)\n",
    "print(contadorErro)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1577b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VerifValList=[]\n",
    "VerifValList.append(\"Acerto - \" + contadorCerto )\n",
    "VerifValList.append(\"Erro - \" + contadorErro )\n",
    "GravarArquivo(VerifValList,'Verif_ValList' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ebc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'Percentage_'+ str(percentageData) +  '/ModelTreinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Percentage_'+ str(percentageData) +  '/train_dataframe', \"wb\") as f:\n",
    "    pickle.dump(train_dataframe, f)\n",
    "with open('Percentage_'+ str(percentageData) +  '/encoder', \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59db5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c145d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebeecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8acbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
