{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afdab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pickle\n",
    "\n",
    "print('fim')\n",
    "percentageData = \"3\"\n",
    "file_to_search = '/home/jupyter/imported/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e53e75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "\n",
    "def GravarArquivo ( data_dict,fname):\n",
    "    if len(data_dict) <=0:\n",
    "        print(\"branco\")\n",
    "    \n",
    "    elif os.path.isfile(fname):\n",
    "    # File exists\n",
    "     with open(fname, 'a+') as outfile:\n",
    "        outfile.seek(outfile.tell() - 2, os.SEEK_SET)\n",
    "        outfile.truncate()\n",
    "        outfile.write(',')\n",
    "        outfile.write(json.dumps(data_dict,ensure_ascii=False, indent=4)[1:-1])\n",
    "        outfile.write(']')\n",
    "        outfile.close() \n",
    "    else: \n",
    "    # Create file\n",
    "     with open(fname, 'w') as outfile:\n",
    "        json.dump(data_dict, outfile, ensure_ascii=False, indent=4) \n",
    "        outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d1e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GravarArquivo2 ( data_dict,fname):\n",
    "    if len(data_dict) <=0:\n",
    "        print(\"branco\")\n",
    "        \n",
    "    elif os.path.isfile(fname):\n",
    "    # File exists\n",
    "     with open(fname, 'a+') as outfile:\n",
    "        outfile.seek(outfile.tell() - 2, os.SEEK_SET)\n",
    "        outfile.truncate()\n",
    "        outfile.write(',')\n",
    "        outfile.write(json.dumps(data_dict,ensure_ascii=False, indent=4)[1:-1])\n",
    "        outfile.write(']')\n",
    "        outfile.close() \n",
    "    else: \n",
    "    # Create file\n",
    "     with open(fname, 'w') as outfile:\n",
    "        json.dump(data_dict, outfile, ensure_ascii=False, indent=4) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "828c6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Percentage_'+ str(percentageData) +  '/train_dataframe', \"rb\") as f:\n",
    "     train_dataframe =  pickle.load(f) \n",
    "with open('Percentage_'+ str(percentageData) +  '/encoder', \"rb\") as f:\n",
    "     encoder =  pickle.load(f)\n",
    "with open('Percentage_'+ str(percentageData) +  '/val_dataframe', \"rb\") as f:\n",
    "     val_dataframe =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validaRede (model ,memory ) : \n",
    "                index=1\n",
    "                #0 - path image \n",
    "                #1 - address \n",
    "                ListasAcertasTrainlist = []\n",
    "                QuestoesCertasList =[]\n",
    "                QuestoesErradasList=[]\n",
    "                QTDERRADA =0 \n",
    "                QTDCERTA=0\n",
    "                for contador in range(len(train_dataframe)) :\n",
    "\n",
    "                    im=cv2.imread(train_dataframe.iloc[contador]['Path'])\n",
    "                    im=cv2.resize(im,(200,200))\n",
    "                    q=train_dataframe.iloc[contador]['Question']  \n",
    "                    q=encoder.encode(q)\n",
    "                    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "                    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "                    q=np.array(q)\n",
    "                    im.resize(1,200,200,3)\n",
    "                    q.resize(1,50)\n",
    "                    ans=model.predict([im,q]) \n",
    "                    decodAns = encoder.decode([np.argmax(ans)])\n",
    "                    if train_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "                        ListasAcertasTrainlist.append(0)\n",
    "                        QuestoesErradasList.append(\"questão nr: \" + str(contador))\n",
    "                        QuestoesErradasList.append(train_dataframe.iloc[contador]['Question'])\n",
    "                        QuestoesErradasList.append( \"certa:\" + train_dataframe.iloc[contador]['Answer'] + \" errada : \" + decodAns) \n",
    "                        QTDERRADA = QTDERRADA+1\n",
    "                        \n",
    "                    else:     \n",
    "                        ListasAcertasTrainlist.append(1)\n",
    "                        QuestoesCertasList.append(\"questão nr: \" + str(contador))\n",
    "                        QuestoesCertasList.append(train_dataframe.iloc[contador]['Question'])\n",
    "                        QuestoesCertasList.append( \"certa:\" + train_dataframe.iloc[contador]['Answer'] + \" preditada : \" + decodAns) \n",
    "                        QTDCERTA = QTDCERTA+1\n",
    "                       \n",
    "                    if (contador%2000) == 0 : \n",
    "                        GravarArquivo (ListasAcertasTrainlist,FolderSource  + '/ResultPredication_Train_' +memory +'.json') \n",
    "                        GravarArquivo2 (QuestoesErradasList,FolderSource  + '/ResultPredication_Train_' +memory +'_Ques_errada.json')  \n",
    "                        GravarArquivo2 (QuestoesCertasList,FolderSource  + '/ResultPredication_Train_' +memory +'_Ques_certa.json')  \n",
    "                        ListasAcertasTrainlist=[]\n",
    "                        QuestoesCertasList =[]\n",
    "                        QuestoesErradasList=[]\n",
    "                QuestoesErradasList.append(\"QTD de questões : \" + str(QTDERRADA))\n",
    "                QuestoesCertasList.append(\"QTD de questões :  \" + str(QTDCERTA))\n",
    "                \n",
    "                if (contador%2000) >= 0 :\n",
    "                    GravarArquivo (ListasAcertasTrainlist,FolderSource +  '/ResultPredication_Train_' +memory +'.json')   \n",
    "                    GravarArquivo2 (QuestoesErradasList,FolderSource +  '/ResultPredication_Train_' +memory +'_Ques_errada.json')    \n",
    "                    GravarArquivo2 (QuestoesCertasList,FolderSource +  '/ResultPredication_Train_' +memory +'_Ques_certa.json')  \n",
    "                   \n",
    "                ListasValidacaolist = []\n",
    "                QuestoesCertasList =[]\n",
    "                QuestoesErradasList=[]\n",
    "                QTDERRADA = 0\n",
    "                QTDCERTA = 0\n",
    "                for contador in   range(len(val_dataframe)) :\n",
    "\n",
    "                    im=cv2.imread(val_dataframe.iloc[contador]['Path'])\n",
    "                    im=cv2.resize(im,(200,200))\n",
    "                    q=val_dataframe.iloc[contador]['Question'] \n",
    "                    q=encoder.encode(q)\n",
    "                    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "                    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "                    q=np.array(q)\n",
    "                    im.resize(1,200,200,3)\n",
    "                    q.resize(1,50)\n",
    "\n",
    "                    ans=model.predict([im,q]) \n",
    "                    decodAns = encoder.decode([np.argmax(ans)])\n",
    "                    if val_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "                        ListasValidacaolist.append(0)\n",
    "                        QuestoesErradasList.append(\"questão nr: \" + str(contador))\n",
    "                        QuestoesErradasList.append(val_dataframe.iloc[contador]['Question'])\n",
    "                        QuestoesErradasList.append( \"certa:\" + val_dataframe.iloc[contador]['Answer'] + \" errada : \" + decodAns) \n",
    "                        QTDERRADA = QTDERRADA+1\n",
    "                    else:     \n",
    "                        ListasValidacaolist.append(1)\n",
    "                        QuestoesCertasList.append(\"questão nr: \" + str(contador))\n",
    "                        QuestoesCertasList.append(val_dataframe.iloc[contador]['Question'])\n",
    "                        QuestoesCertasList.append( \"certa:\" + val_dataframe.iloc[contador]['Answer'] + \" preditada : \" + decodAns) \n",
    "                        QTDCERTA = QTDCERTA+1\n",
    "                        \n",
    "                    if (contador%2000) == 0 : \n",
    "                        GravarArquivo (ListasValidacaolist,FolderSource + '/ResultPredication_Val_' +memory +'.json')   \n",
    "                        GravarArquivo2 (QuestoesCertasList,FolderSource +  '/ResultPredication_Val_' +memory +'_Ques_Certas.json')  \n",
    "                        GravarArquivo2 (QuestoesErradasList,FolderSource +  '/ResultPredication_Val_' +memory +'_Ques_Errada.json')  \n",
    "                        QuestoesCertasList =[]\n",
    "                        QuestoesErradasList=[]               \n",
    "                        ListasValidacaolist=[]\n",
    "                        \n",
    "                QuestoesErradasList.append(\"QTD de questões : \" + str(QTDERRADA))\n",
    "                QuestoesCertasList.append(\"QTD de questões :  \" + str(QTDCERTA))\n",
    "                if (contador%2000) >= 0 :      \n",
    "                      GravarArquivo (ListasValidacaolist,FolderSource + '/ResultPredication_Val_' +memory +'.json')   \n",
    "                      GravarArquivo2 (QuestoesCertasList,FolderSource +  '/ResultPredication_Val_' +memory +'_Ques_Certas.json')  \n",
    "                      GravarArquivo2 (QuestoesErradasList,FolderSource +  '/ResultPredication_Val_' +memory +'_Ques_Errada.json')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4335442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 256)      26112       text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "image_input (InputLayer)        [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 512)      1050624     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functiona (None, 7, 7, 1280)   2257984     image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 512)      1574912     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           mobilenetv2_1.00_224[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1024)         4198400     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2304)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 102)          235110      concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 9,343,142\n",
      "Trainable params: 9,309,030\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model('Percentage_'+ str(percentageData) +\"/ModelTreinamento\")\n",
    "model2.summary()\n",
    "file_to_search = '/home/jupyter/imported/'\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0233cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branco\n",
      "branco\n"
     ]
    }
   ],
   "source": [
    "FolderSource = file_to_search  + \"Percentage_3\" \n",
    "validaRede(model2,\"fullmemeory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('oi')\n",
    "\n",
    "folders = dirs = [d for d in os.listdir(file_to_search) if os.path.isdir(os.path.join(file_to_search, d))]\n",
    "\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    if 'Percentage_0.1'  in folder:\n",
    "        qtd = 0 \n",
    "     \n",
    "        vocab_set=set()#set object used to store the vocabulary\n",
    "        partSplit = folder.split('_')\n",
    "        perc = partSplit[1]\n",
    "        FolderSource = file_to_search + '//' + folder \n",
    "        Files = [f for f in os.listdir(FolderSource) if isfile(join(FolderSource, f))]\n",
    "        posQues =[]\n",
    "        valList=[]\n",
    "        trainList=[]\n",
    "        memorys = []\n",
    "                     \n",
    "        for File in Files:\n",
    "                print (File)\n",
    "                if 'ckpt' in File and 'index' in File:\n",
    "                    obj=[]\n",
    "                    obj.append(perc)\n",
    "                    obj.append(File[:-6])\n",
    "                    memorys.append(obj)\n",
    "            \n",
    "        \n",
    "        \n",
    "        print('memorys ')\n",
    "        \n",
    "        for memory in memorys :\n",
    "            print(memory)\n",
    "            #'weights-100' in  memory[1]\n",
    "            if 1==1 :\n",
    "                print(memory[1])\n",
    "           \n",
    "\n",
    "                filepath=FolderSource + '//' + memory[1]  \n",
    "                print(filepath)\n",
    "                model2 = tf.keras.models.load_model('Percentage_'+ str(percentageData) +\"/ModelTreinamento\")   \n",
    "                \n",
    "                model2.load_weights(filepath)\n",
    "                model2.summary()\n",
    "                validaRede(model2,memory[1])\n",
    "                \n",
    "                   \n",
    "    \n",
    "                \n",
    "print('fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b74b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd0a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
