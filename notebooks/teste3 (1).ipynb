{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d232e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (1.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tensorflow_datasets in /opt/conda/lib/python3.7/site-packages (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (2.25.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (4.61.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (21.2.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (3.17.3)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (1.19.5)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (0.12.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.5.30)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting tensorflow.io\n",
      "  Downloading tensorflow_io-0.20.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (22.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.7 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow<2.7.0,>=2.6.0\n",
      "  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 7.6 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.20.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.20.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 65.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.6.3)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 64.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (2.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.17.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.15.0)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 67.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.12.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.3.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 37.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 37.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.1.2)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.32.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (49.6.0.post20210108)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7.0,>=2.6.0->tensorflow.io) (3.5.0)\n",
      "Building wheels for collected packages: clang\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=e18caa0c13dad90aa9d8d6e9164b5c847df97ef49274e83875f7be64e1326389\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
      "Successfully built clang\n",
      "Installing collected packages: grpcio, cached-property, tensorflow-estimator, keras, h5py, gast, clang, tensorflow-io-gcs-filesystem, tensorflow, tensorflow.io\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed cached-property-1.5.2 clang-5.0 gast-0.4.0 grpcio-1.39.0 h5py-3.1.0 keras-2.6.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 tensorflow-io-gcs-filesystem-0.20.0 tensorflow.io-0.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 02:31:44.678617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-09-03 02:31:44.678681: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim\n"
     ]
    }
   ],
   "source": [
    "print('oi')\n",
    "! pip install tensorflow\n",
    "! pip install tensorflow_datasets\n",
    "! pip install tensorflow.io\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.preprocessing import text\n",
    "\n",
    "print('fim')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa6784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e577651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs : 0\n",
      "Tensorflow GPU : True\n",
      "Porcentual0.01\n",
      "********* lenght *****************\n",
      "69\n",
      "K\n",
      "68\n",
      "0\n",
      "K\n",
      "13\n",
      "13\n",
      "passou\n",
      "*********** vocab set *********\n",
      "89\n",
      "Percentage_0.01/vocab_set_14.json\n",
      "foi\n",
      "foi1\n",
      "{'metal', 'or', 'color', 'Are', 'behind', 'other', 'in', 'cubes', 'How', 'is', 'size', 'it', 'another', 'Does', 'any', 'yes', 'material', 'blocks', 'left', 'on', 'number', 'large', 'rubber', 'right', 'than', 'side', 'cylinders', 'thing', 'cyan', 'does', 'shiny', 'metallic', 'spheres', 'both', '1', 'matte', 'as', 'either', 'brown', 'things', 'There', 'a', 'gray', 'the', 'that', 'else', 'objects', 'less', 'purple', 'cube', 'has', 'no', 'sphere', '0', 'block', 'Is', 'cylinder', 'its', 'are', 'red', 'same', 'many', 'made', 'visible', 'more', 'green', 'anything', 'balls', 'what', 'shape', 'The', 'object', 'big', 'What', 'and', 'of', 'fewer', 'yellow', 'blue', '2', 'ball', 'small', 'how', 'have', 'there', 'tiny', 'front', 'greater', 'to'}\n",
      "passou2\n",
      "*********** vocab set *********\n",
      "89\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 256)      23040       text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "image_input (InputLayer)        [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 50, 512)      1050624     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functiona (None, 7, 7, 1280)   2257984     image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 50, 512)      1574912     bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           mobilenetv2_1.00_224[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1024)         4198400     bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2304)         0           global_average_pooling2d_2[0][0] \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 90)           207450      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,312,410\n",
      "Trainable params: 9,278,298\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 32s 297ms/step - loss: 3.6123 - sparse_categorical_accuracy: 0.2029 - val_loss: 17.6136 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 18s 258ms/step - loss: 2.7984 - sparse_categorical_accuracy: 0.1739 - val_loss: 12.7312 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 18s 258ms/step - loss: 2.5386 - sparse_categorical_accuracy: 0.2029 - val_loss: 8.0155 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 18s 256ms/step - loss: 2.4567 - sparse_categorical_accuracy: 0.2174 - val_loss: 5.8495 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 18s 257ms/step - loss: 2.4467 - sparse_categorical_accuracy: 0.2319 - val_loss: 4.8289 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 18s 257ms/step - loss: 2.3332 - sparse_categorical_accuracy: 0.3333 - val_loss: 3.3925 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 18s 257ms/step - loss: 2.1646 - sparse_categorical_accuracy: 0.2899 - val_loss: 2.9167 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 18s 256ms/step - loss: 2.1778 - sparse_categorical_accuracy: 0.3188 - val_loss: 2.3350 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 18s 265ms/step - loss: 2.0066 - sparse_categorical_accuracy: 0.3333 - val_loss: 2.4353 - val_sparse_categorical_accuracy: 0.3571\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 18s 259ms/step - loss: 1.9144 - sparse_categorical_accuracy: 0.3188 - val_loss: 2.8449 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 18s 256ms/step - loss: 1.8605 - sparse_categorical_accuracy: 0.3333 - val_loss: 2.6867 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 18s 257ms/step - loss: 1.8509 - sparse_categorical_accuracy: 0.2899 - val_loss: 2.7977 - val_sparse_categorical_accuracy: 0.1429\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 18s 258ms/step - loss: 1.9700 - sparse_categorical_accuracy: 0.2754 - val_loss: 2.5191 - val_sparse_categorical_accuracy: 0.3571\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 18s 257ms/step - loss: 1.8471 - sparse_categorical_accuracy: 0.3478 - val_loss: 2.8686 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 18s 258ms/step - loss: 1.7039 - sparse_categorical_accuracy: 0.3188 - val_loss: 2.8332 - val_sparse_categorical_accuracy: 0.2143\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 18s 258ms/step - loss: 1.5840 - sparse_categorical_accuracy: 0.3913 - val_loss: 2.7047 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 18s 256ms/step - loss: 1.5136 - sparse_categorical_accuracy: 0.4203 - val_loss: 2.8700 - val_sparse_categorical_accuracy: 0.1429\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 18s 256ms/step - loss: 1.2469 - sparse_categorical_accuracy: 0.4783 - val_loss: 2.9715 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 19/20\n",
      "26/69 [==========>...................] - ETA: 10s - loss: 1.8261 - sparse_categorical_accuracy: 0.3846"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-648ae71a210b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m             history = model.fit(train_dataset,\n\u001b[1;32m    222\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 epochs=20)\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Check GPU is available for training or not Or whether the tensorflow version can utilize gpu \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Number of GPUs :\", len(physical_devices)) \n",
    "print(\"Tensorflow GPU :\",tf.test.is_built_with_cuda())\n",
    "if len(physical_devices)>0:\n",
    "    device=\"/GPU:0\"\n",
    "else:\n",
    "    device=\"/CPU:0\"\n",
    "\n",
    "listlenghData = [0.01]\n",
    "for percentageData in listlenghData:\n",
    "        \n",
    "        print('Porcentual' + str(percentageData ))\n",
    "       #train_dataframe and val_dataframe stores the path to the images and respective questions and answers\n",
    "        lenghtData = 0\n",
    "        posTrain = []\n",
    "        posQues = []\n",
    "        trainList=[]\n",
    "        k=0\n",
    "        with open('/home/kaggle/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_train_questions.json') as f:\n",
    "            data = json.load(f)\n",
    "            qtdData = len(data['questions'])\n",
    "            lenghtDataTrain = int(qtdData * (percentageData/100))\n",
    "            print('********* lenght *****************')\n",
    "            print(lenghtDataTrain)\n",
    "            if lenghtDataTrain == 0 : \n",
    "                lenghtDataTrain = len(data['questions'])\n",
    "            \n",
    "            pos =0 \n",
    "        \n",
    "            for k in range(lenghtDataTrain):\n",
    "                # if (lenghtData != len(data['questions'])): \n",
    "                #    while  (pos in posTrain):\n",
    "                #        pos= random.randrange(1, qtdData-1, 3)\n",
    "                #else :\n",
    "                #    pos = k \n",
    "                posTrain.append(k)\n",
    "                i = data['questions'][k]\n",
    "                temp=[]\n",
    "                for path in glob.glob('/home/kaggle/input/clevr-dataset/CLEVR_v1.0/images/train/'+i['image_filename']): \n",
    "                    temp.append(path)\n",
    "                temp.append(i['question'])\n",
    "                temp.append(i['answer'])\n",
    "                trainList.append(temp)\n",
    "        f.close()\n",
    "        labels=['Path','Question','Answer']\n",
    "        train_dataframe = pd.DataFrame.from_records(trainList, columns=labels)#training Dataframe \n",
    "        del(data)\n",
    "        del(trainList)\n",
    "        print('K')\n",
    "        print(k)\n",
    "        print(pos)\n",
    "        BATCH_SIZE=1\n",
    "        k=0\n",
    "        pos=0\n",
    "        valList=[]\n",
    "        lenghtData = 0 \n",
    "        with open('/home/kaggle/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_val_questions.json') as f:\n",
    "            data = json.load(f)\n",
    "            qtdData = len(data['questions'])\n",
    "            lenghtData = int(qtdData * (percentageData/100))\n",
    "            \n",
    "            if lenghtData == 0 : \n",
    "                lenghtData = len(data['questions'])\n",
    "                \n",
    "            for k in range(lenghtData):\n",
    "                #if (lenghtData != len(data['questions'])): \n",
    "                #    while  (pos in posQues):\n",
    "                #        pos= random.randrange(1, qtdData-1, 3)\n",
    "                #else :\n",
    "                pos = k   \n",
    "                posQues.append(pos)\n",
    "                i = data['questions'][pos]\n",
    "                temp=[]\n",
    "                for path in glob.glob('/home/kaggle/input/clevr-dataset/CLEVR_v1.0/images/val/'+i['image_filename']): \n",
    "                    temp.append(path)\n",
    "                temp.append(i['question'])\n",
    "                temp.append(i['answer'])\n",
    "                valList.append(temp)\n",
    "\n",
    "        print('K')\n",
    "        print(k)\n",
    "        print(pos)\n",
    "        f.close()\n",
    "        val_dataframe = pd.DataFrame.from_records(valList, columns=labels)#validation Dataframe\n",
    "        del(data)\n",
    "        del(valList)\n",
    "        val_dataframe.head()\n",
    "\n",
    "        vocab_set=set()#set object used to store the vocabulary\n",
    "        #\n",
    "        tokenizer = tfds.features.text.Tokenizer()\n",
    "        print('passou')\n",
    "\n",
    "        for i in val_dataframe['Question']:\n",
    "            vocab_set.update(tokenizer.tokenize(i))\n",
    "        for i in train_dataframe['Question']:\n",
    "            vocab_set.update(tokenizer.tokenize(i))\n",
    "        for i in val_dataframe['Answer']:\n",
    "            vocab_set.update(tokenizer.tokenize(i))\n",
    "        for i in train_dataframe['Answer']:\n",
    "            vocab_set.update(tokenizer.tokenize(i))\n",
    "        #\n",
    "        #Creating an Encoder and a Function to preprocess the text data during the training and inference    \n",
    "        #deprecated\n",
    "        encoder= tfds.features.text.TokenTextEncoder(vocab_set)\n",
    "        index=1\n",
    "        print( '*********** vocab set *********')\n",
    "        print(len(vocab_set))\n",
    "        IMG_SIZE=(200,200)\n",
    "        print('Percentage_'+ str(percentageData) + '/'+ 'vocab_set_' +str(lenghtData) + '.json')\n",
    "        os.makedirs(os.path.dirname('Percentage_'+ str(percentageData) + '/'+ 'vocab_set_' +str(lenghtData) + '.json'), exist_ok=True)\n",
    "        print ('foi')   \n",
    "        with open('Percentage_'+ str(percentageData) + '/'+ 'vocab_set_' +str(lenghtData) + '.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(list(vocab_set), f, ensure_ascii=False, indent=4)\n",
    "        print('foi1')\n",
    "        print(vocab_set)\n",
    "        #Function that uses the encoder created to encode the input question and answer string\n",
    "        def encode_fn(text):\n",
    "            return np.array(encoder.encode(text.numpy()))\n",
    "                  \n",
    "        with open('Percentage_'+ str(percentageData) + '/train_datalenght'+str(lenghtDataTrain) + '.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(posTrain, f, ensure_ascii=False, indent=4)\n",
    "        with open('Percentage_'+ str(percentageData) + '/ques_datalenght'+str(lenghtData) + '.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(posQues, f, ensure_ascii=False, indent=4) \n",
    "        print('passou2')\n",
    "        #Function to load and decode the image from the file paths in the dataframe and use the encoder function\n",
    "        def preprocess(ip,ans):\n",
    "            img,ques=ip#ip is a list containing image paths and questions\n",
    "            img=tf.io.read_file(img)\n",
    "            img=tf.image.decode_jpeg(img,channels=3)\n",
    "            # quantos canais de cores tem \n",
    "            img=tf.image.resize(img,IMG_SIZE)\n",
    "            img=tf.math.divide(img, 255)# \n",
    "            #The question string is converted to encoded list with fixed size of 50 with padding with 0 value\n",
    "            ques=tf.py_function(encode_fn,inp=[ques],Tout=tf.int32)\n",
    "            paddings = [[0, 50-tf.shape(ques)[0]]]\n",
    "            ques = tf.pad(ques, paddings, 'CONSTANT', constant_values=0)\n",
    "            ques.set_shape([50])#Explicit shape must be defined in order to create the Input pipeline\n",
    "\n",
    "            #The Answer is also encoded \n",
    "            ans=tf.py_function(encode_fn,inp=[ans],Tout=tf.int32)\n",
    "            ans.set_shape([1])\n",
    "\n",
    "            return (img,ques),ans\n",
    "\n",
    "        def create_pipeline(dataframe):\n",
    "            raw_df=tf.data.Dataset.from_tensor_slices(((dataframe['Path'],dataframe['Question']),dataframe['Answer']))\n",
    "            df=raw_df.map(preprocess)#Preprocessing function is applied to the dataset\n",
    "            df=df.batch(BATCH_SIZE)#The dataset is batched\n",
    "            return df\n",
    "\n",
    "        #The training and validation Dataset objects are created\n",
    "        train_dataset=create_pipeline(train_dataframe)\n",
    "        validation_dataset=create_pipeline(val_dataframe)\n",
    "\n",
    "        #Creating the CNN model for image processing\n",
    "\n",
    "\n",
    "        CNN_Input=tf.keras.layers.Input(shape=(200,200,3),name='image_input')\n",
    "\n",
    "        mobilenetv2=tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(200,200,3), alpha=1.0, include_top=False,\n",
    "                                                              weights='imagenet', input_tensor=CNN_Input)\n",
    "\n",
    "        CNN_model=tf.keras.models.Sequential()\n",
    "        CNN_model.add(CNN_Input)\n",
    "        CNN_model.add(mobilenetv2)\n",
    "        CNN_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "        print( '*********** vocab set *********')\n",
    "        print(len(vocab_set))\n",
    "        #Creating the RNN model for text processing\n",
    "        RNN_model=tf.keras.models.Sequential()\n",
    "\n",
    "        RNN_Input=tf.keras.layers.Input(shape=(50),name='text_input')\n",
    "        RNN_model.add(RNN_Input)\n",
    "        RNN_model.add(tf.keras.layers.Embedding (len(vocab_set)+1,256))\n",
    "        RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,stateful=False,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "        RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,stateful=False,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "        RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512,stateful=False,return_sequences=False,recurrent_initializer='glorot_uniform')))\n",
    "\n",
    "\n",
    "        concat=tf.keras.layers.concatenate([CNN_model.output,RNN_model.output])\n",
    "        dense_out=tf.keras.layers.Dense(len(vocab_set)+1,activation='softmax',name='output')(concat)\n",
    "\n",
    "        model = tf.keras.Model(inputs=[CNN_Input,RNN_Input],\n",
    "                            outputs=dense_out)\n",
    "        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "                    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "      \n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        def scheduler(epoch):\n",
    "            if epoch < 1:\n",
    "                return 0.001\n",
    "            else:\n",
    "                return 0.001 * tf.math.exp(0.1 * (1 - epoch))\n",
    "        \n",
    "        \n",
    "        \n",
    "        LRS = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        csv_callback=tf.keras.callbacks.CSVLogger('Percentage_'+ str(percentageData) + \"/Training Parameters.csv\", separator=',', append=False )\n",
    "      \n",
    "        filepath='Percentage_'+ str(percentageData) + '/weights-improvement-{epoch:02d}.ckpt'\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='epoch', verbose=1,save_weights_only=True)\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        epoch = 0\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "\n",
    "        model.save_weights(checkpoint_path.format(epoch=0,val_loss=0))\n",
    "   \n",
    "        \n",
    "\n",
    "        with tf.device(device):\n",
    "            history = model.fit(train_dataset,\n",
    "                validation_data=validation_dataset,\n",
    "                epochs=20)\n",
    "\n",
    "        train_dataframe.iloc[index]['Path']\n",
    "        print(\"grafics\")\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "        history.history\n",
    "        hist.tail()\n",
    "\n",
    "        def plot_loss(history):\n",
    "            plt.plot(history.history['loss'], label='training loss')\n",
    "            plt.plot(history.history['val_loss'], label=' validation loss')\n",
    "            #plt.ylim([0, 10])\n",
    "            plt.xlabel('Epopch')\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig( 'Percentage_'+ str(percentageData) + '/error_datalenght'+str(lenghtData) + '.png')\n",
    "            plt.show()\n",
    "\n",
    "        def plot_acc(history):  \n",
    "            plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "            plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "            plt.title('model accuracy')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.savefig('Percentage_'+ str(percentageData) + '/accuracy_datalenght'+str(lenghtData) + '.png')\n",
    "            plt.show()\n",
    "        plot_loss(history)\n",
    "        plot_acc(history)\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a026d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "contadorCerto =0\n",
    "contadorErro =0\n",
    "for contador in range(69) :\n",
    "   \n",
    "    im=cv2.imread(train_dataframe.iloc[contador]['Path'])\n",
    "    im=cv2.resize(im,(200,200))\n",
    "    q=train_dataframe.iloc[contador]['Question'] \n",
    "    q=encoder.encode(q)\n",
    "    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "    q=np.array(q)\n",
    "    im.resize(1,200,200,3)\n",
    "    q.resize(1,50)\n",
    "    ans=model.predict([im,q]) \n",
    "    decodAns = encoder.decode([np.argmax(ans)])\n",
    "    if train_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "        contadorErro = contadorErro +1\n",
    "    else:     \n",
    "        contadorCerto = contadorCerto +1\n",
    "      \n",
    "print(contadorCerto)\n",
    "print(contadorErro)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be516f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
