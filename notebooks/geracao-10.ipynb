{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90479d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.3.1\n",
      "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.7.1)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (2.10.0)\n",
      "Installing collected packages: keras-applications, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tensorflow==2.4.1 in /opt/conda/lib/python3.7/site-packages (2.4.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.12.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting tensorflow-gpu==2.4.1\n",
      "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |██████████████████████████████▊ | 379.0 MB 104.5 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 394.3 MB 9.8 kB/s \n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (0.12.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.12)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (0.37.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.34.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.5.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting pandas==1.2.5\n",
      "  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas==1.2.5) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.2.5) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.2.5) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.2.5) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.2\n",
      "    Uninstalling pandas-1.3.2:\n",
      "      Successfully uninstalled pandas-1.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "caip-notebooks-serverextension 1.0.0 requires google-cloud-bigquery-storage, which is not installed.\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-1.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-18 01:23:15.545542: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-09-18 01:23:15.545601: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install keras==2.3.1\n",
    "! pip install tensorflow==2.4.1\n",
    "! pip install tensorflow-gpu==2.4.1\n",
    "\n",
    "!pip install pandas==1.2.5\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "print('fim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ebcd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)\n",
    "start_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f94b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GravarArquivo ( data_dict,fname):\n",
    "    fname = fname +\"_\" +str(len(data_dict)) + '.json'\n",
    "    print(\"gravar arquivo: \" + fname + \" qtd: \" +  str(len(data_dict)))\n",
    "    os.makedirs('Percentage_'+ str(percentageData) , exist_ok=True)\n",
    "    fname = 'Percentage_'+ str(percentageData) + \"/\" + fname\n",
    "    # Create file\n",
    "    with open(fname, 'w') as outfile:\n",
    "        json.dump(data_dict, outfile, ensure_ascii=False, indent=4) \n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83e823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "            plt.plot(history.history['loss'], label='training loss')\n",
    "            plt.plot(history.history['val_loss'], label=' validation loss')\n",
    "            #plt.ylim([0, 10])\n",
    "            plt.xlabel('Epopch')\n",
    "            plt.ylabel('Error')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig( 'Percentage_'+ str(percentageData) + '/error_datalenght.png')\n",
    "            plt.show()\n",
    "\n",
    "def plot_acc(history):  \n",
    "            plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "            plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "            plt.title('model accuracy')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.savefig('Percentage_'+ str(percentageData) + '/accuracy_datalenght.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94342e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs : 0\n",
      "Tensorflow GPU : True\n"
     ]
    }
   ],
   "source": [
    "#Check GPU is available for training or not Or whether the tensorflow version can utilize gpu \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Number of GPUs :\", len(physical_devices)) \n",
    "print(\"Tensorflow GPU :\",tf.test.is_built_with_cuda())\n",
    "if len(physical_devices)>0:\n",
    "    device=\"/GPU:0\"\n",
    "else:\n",
    "    device=\"/CPU:0\"\n",
    "percentageData = 10\n",
    "posTrainList=[]\n",
    "posValList=[]\n",
    "BATCH_SIZE=1\n",
    "IMG_SIZE=(200,200)\n",
    "QtdEpocasGravarCHKP = 2\n",
    "Epochs = 10\n",
    "lenghtDataTrain = 0\n",
    "lenghtDataVal =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e230a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n"
     ]
    }
   ],
   "source": [
    "trainList=[]\n",
    "\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_train_questions.json') as f:\n",
    "    print('oi')\n",
    "    data = json.load(f)\n",
    "    lenghtDataTrain = int(len(data['questions']) * (percentageData/100))\n",
    "    print(lenghtDataTrain)\n",
    "    for K in range(lenghtDataTrain):\n",
    "        i = data['questions'][K]\n",
    "       \n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/train/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "           \n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        trainList.append(temp)\n",
    "        posTrainList.append(K)\n",
    "f.close()\n",
    "labels=['Path','Question','Answer']\n",
    "train_dataframe = pd.DataFrame.from_records(trainList, columns=labels)#training Dataframe \n",
    "del(data)\n",
    "del(trainList)\n",
    "print('fim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "valList=[]\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_val_questions.json') as f:\n",
    "    data = json.load(f)\n",
    "    lenghtDataVal = int(len(data['questions']) * (percentageData/100))\n",
    "    for K in range(lenghtDataVal):\n",
    "    \n",
    "       \n",
    "        i = data['questions'][K]\n",
    "        \n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/val/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        valList.append(temp)\n",
    "        posValList.append(K)\n",
    "f.close() \n",
    "\n",
    "val_dataframe = pd.DataFrame.from_records(valList, columns=labels)#validation Dataframe\n",
    "del(data)\n",
    "del(valList)\n",
    "val_dataframe.head()\n",
    "print('passou carregou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0a10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b312948",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set=set()#set object used to store the vocabulary\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "valtest=[]\n",
    "\n",
    "valList =[]\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_train_questions.json') as f:\n",
    "    print('oi')\n",
    "    data = json.load(f)\n",
    "   \n",
    "    print(int(len(data['questions'])))\n",
    "    for K in range(int(len(data['questions']))):\n",
    "        i = data['questions'][K]\n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/train/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        valtest.append(temp)\n",
    "   \n",
    "f.close()\n",
    "labels=['Path','Question','Answer']\n",
    "train_dataframe2 = pd.DataFrame.from_records(valtest, columns=labels)#training Dataframe \n",
    "del(data)\n",
    "del(valtest)\n",
    "print('fim')\n",
    "\n",
    "valList=[]\n",
    "with open('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/questions/CLEVR_val_questions.json') as f:\n",
    "    data = json.load(f)\n",
    "    lenghtDataVal = int(len(data['questions']) * (percentageData/100))\n",
    "    for K in range(int(len(data['questions']))):\n",
    "        i = data['questions'][K]\n",
    "        temp=[]\n",
    "        for path in glob.glob('/home/jupyter/input/clevr-dataset/CLEVR_v1.0/images/val/'+i['image_filename']): \n",
    "            temp.append(path)\n",
    "        temp.append(i['question'])\n",
    "        temp.append(i['answer'])\n",
    "        valList.append(temp)\n",
    "        \n",
    "f.close() \n",
    "\n",
    "val_dataframe2 = pd.DataFrame.from_records(valList, columns=labels)#validation Dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in val_dataframe2['Question']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in train_dataframe2['Question']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in val_dataframe2['Answer']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "for i in train_dataframe2['Answer']:\n",
    "    vocab_set.update(tokenizer.tokenize(i))\n",
    "    \n",
    "vocab_set.update('12aaaa')\n",
    "vocab_set.update('1234sssa')\n",
    "\n",
    "#\n",
    "#Creating an Encoder and a Function to preprocess the text data during the training and inference    \n",
    "    \n",
    "encoder=tfds.features.text.TokenTextEncoder(vocab_set)\n",
    "index=2\n",
    "print(\"Testing the Encoder with sample questions - \\n \")\n",
    "example_text=encoder.encode(train_dataframe['Question'][index])\n",
    "print(\"Original Text = \"+train_dataframe['Question'][index])\n",
    "print(\"After Encoding = \"+str(example_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GravarArquivo(posValList,'Val_pos' )\n",
    "GravarArquivo(posTrainList,'Train_pos' )\n",
    "GravarArquivo(list(vocab_set), 'Vocab_set' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function that uses the encoder created to encode the input question and answer string\n",
    "def encode_fn(text):\n",
    "    return np.array(encoder.encode(text.numpy()))\n",
    "\n",
    "\n",
    "#Function to load and decode the image from the file paths in the dataframe and use the encoder function\n",
    "def preprocess(ip,ans):\n",
    "    img,ques=ip#ip is a list containing image paths and questions\n",
    "    img=tf.io.read_file(img)\n",
    "    img=tf.image.decode_jpeg(img,channels=3)\n",
    "    # quantos canais de cores tem \n",
    "    img=tf.image.resize(img,IMG_SIZE)\n",
    "    img=tf.math.divide(img, 255)# \n",
    "    #The question string is converted to encoded list with fixed size of 50 with padding with 0 value\n",
    "    ques=tf.py_function(encode_fn,inp=[ques],Tout=tf.int32)\n",
    "    paddings = [[0, 50-tf.shape(ques)[0]]]\n",
    "    ques = tf.pad(ques, paddings, 'CONSTANT', constant_values=0)\n",
    "    ques.set_shape([50])#Explicit shape must be defined in order to create the Input pipeline\n",
    "    \n",
    "    #The Answer is also encoded \n",
    "    ans=tf.py_function(encode_fn,inp=[ans],Tout=tf.int32)\n",
    "    ans.set_shape([1])\n",
    "    print(ans)\n",
    "    return (img,ques),ans\n",
    "    \n",
    "def create_pipeline(dataframe):\n",
    "    raw_df=tf.data.Dataset.from_tensor_slices(((dataframe['Path'],dataframe['Question']),dataframe['Answer']))\n",
    "    df=raw_df.map(preprocess)#Preprocessing function is applied to the dataset\n",
    "    df=df.batch(BATCH_SIZE)#The dataset is batched\n",
    "    return df\n",
    "\n",
    "#The training and validation Dataset objects are created\n",
    "train_dataset=create_pipeline(train_dataframe)\n",
    "validation_dataset=create_pipeline(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the CNN model for image processing\n",
    "\n",
    "\n",
    "CNN_Input=tf.keras.layers.Input(shape=(200,200,3),name='image_input')\n",
    "\n",
    "mobilenetv2=tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(200,200,3), alpha=1.0, include_top=False,\n",
    "                                                      weights='imagenet', input_tensor=CNN_Input)\n",
    "\n",
    "CNN_model=tf.keras.models.Sequential()\n",
    "CNN_model.add(CNN_Input)\n",
    "CNN_model.add(mobilenetv2)\n",
    "CNN_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "\n",
    "#Creating the RNN model for text processing\n",
    "RNN_model=tf.keras.models.Sequential()\n",
    "\n",
    "RNN_Input=tf.keras.layers.Input(shape=(50),name='text_input')\n",
    "RNN_model.add(RNN_Input)\n",
    "RNN_model.add(tf.keras.layers.Embedding (len(vocab_set)+1,256))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True,recurrent_initializer='glorot_uniform')))\n",
    "RNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512,return_sequences=False,recurrent_initializer='glorot_uniform')))\n",
    "\n",
    "\n",
    "concat=tf.keras.layers.concatenate([CNN_model.output,RNN_model.output])\n",
    "dense_out=tf.keras.layers.Dense(len(vocab_set)+1,activation='softmax',name='output')(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[CNN_Input,RNN_Input],\n",
    "                    outputs=dense_out)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(QtdEpocasGravarCHKP*lenghtDataTrain)\n",
    "print(QtdEpocasGravarCHKP)\n",
    "print(lenghtDataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4218b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Percentage_'+ str(percentageData) +  '/train_dataframe', \"wb\") as f:\n",
    "    pickle.dump(train_dataframe, f)\n",
    "with open('Percentage_'+ str(percentageData) +  '/encoder', \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "with open('Percentage_'+ str(percentageData) +  '/val_dataframe', \"wb\") as f:\n",
    "    pickle.dump(val_dataframe, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scheduler(epoch):\n",
    "  if epoch < 1:\n",
    "    return 0.001\n",
    "  else:\n",
    "    return 0.001 * tf.math.exp(0.1 * (1 - epoch))\n",
    "\n",
    "checkpoint_path = 'Percentage_'+ str(percentageData) + '/weights-{epoch:03d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=QtdEpocasGravarCHKP*lenghtDataTrain)\n",
    "\n",
    "print(QtdEpocasGravarCHKP*lenghtDataTrain)\n",
    "\n",
    "#LRS = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "csv_callback=tf.keras.callbacks.CSVLogger(\n",
    "   'Percentage_'+ str(percentageData) + '/'+ \"Training Parameters.csv\",\n",
    "    separator=',', append=False\n",
    ")\n",
    "\n",
    "\n",
    "with tf.device(device) :\n",
    "    history =  model.fit(train_dataset,\n",
    "              validation_data=validation_dataset,\n",
    "              callbacks=[csv_callback,cp_callback],\n",
    "              epochs=Epochs)\n",
    "\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "history.history\n",
    "hist.tail()\n",
    "#plot_loss(history)\n",
    "#plot_acc(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ecb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "history.history\n",
    "hist.tail()\n",
    "plot_loss(history)\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32622397",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (' *************** vocab se *************************')\n",
    "for voc in vocab_set:\n",
    " print(voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "contadorCerto =0\n",
    "contadorErro =0 \n",
    "ArrayQuestoesCertas =[]\n",
    "ArrarQuestoesErradas=[]\n",
    "\n",
    "for contador in range(lenghtDataTrain) :\n",
    "   \n",
    "    im=cv2.imread(train_dataframe.iloc[contador]['Path'])\n",
    "    im=cv2.resize(im,(200,200))\n",
    "    q=train_dataframe.iloc[contador]['Question'] \n",
    "    q=encoder.encode(q)\n",
    "    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "    q=np.array(q)\n",
    "    im.resize(1,200,200,3)\n",
    "    q.resize(1,50)\n",
    "    ans=model.predict([im,q]) \n",
    "    decodAns = encoder.decode([np.argmax(ans)])\n",
    "        \n",
    "    \n",
    "    if train_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "        ArrarQuestoesErradas.append (\"qestão numero : \" + str(contador))\n",
    "        ArrarQuestoesErradas.append(train_dataframe.iloc[contador]['Question'])\n",
    "        ArrarQuestoesErradas.append('Repost errada: ' +decodAns + \" resp certa:\" + train_dataframe.iloc[contador]['Answer']) \n",
    "        contadorErro = contadorErro +1\n",
    "    else:\n",
    "        ArrayQuestoesCertas.append(\"qestão numero : \" + str(contador))\n",
    "        ArrayQuestoesCertas.append(train_dataframe.iloc[contador]['Question'])\n",
    "        ArrayQuestoesCertas.append(  decodAns)\n",
    "        ArrayQuestoesCertas.append(train_dataframe.iloc[contador]['Answer'])\n",
    "        contadorCerto = contadorCerto +1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"questoes certas\" + str(contadorCerto))\n",
    "print( \"questoes erradas\" + str(contadorErro))\n",
    "VerifTrainList=[]\n",
    "VerifTrainList.append(\"Acerto - \" + str(contadorCerto))\n",
    "VerifTrainList.append(\"Erro - \" + str(contadorErro ))\n",
    "GravarArquivo(VerifTrainList,'Verif_Train_resumo' )\n",
    "GravarArquivo(ArrayQuestoesCertas,'Verif_train_questoescertas' )\n",
    "GravarArquivo(ArrarQuestoesErradas,'Verif_train_questoeserradas' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "contadorCerto =0\n",
    "contadorErro =0 \n",
    "ArrayQuestoesCertas =[]\n",
    "ArrarQuestoesErradas=[]\n",
    "\n",
    "for contador in range(lenghtDataVal) :\n",
    "   \n",
    "    im=cv2.imread(val_dataframe.iloc[contador]['Path'])\n",
    "    im=cv2.resize(im,(200,200))\n",
    "    q=val_dataframe.iloc[contador]['Question'] \n",
    "    q=encoder.encode(q)\n",
    "    paddings = [[0, 50-tf.shape(q)[0]]]\n",
    "    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n",
    "    q=np.array(q)\n",
    "    im.resize(1,200,200,3)\n",
    "    q.resize(1,50)\n",
    "    ans=model.predict([im,q]) \n",
    "    decodAns = encoder.decode([np.argmax(ans)])\n",
    "    if val_dataframe.iloc[contador]['Answer'] != decodAns :\n",
    "        ArrarQuestoesErradas.append (\"qestão numero : \" + str(contador))\n",
    "        ArrarQuestoesErradas.append(val_dataframe.iloc[contador]['Question'])\n",
    "        ArrarQuestoesErradas.append( \" errado - \" + decodAns + \" certo - \" + val_dataframe.iloc[contador]['Answer'] )\n",
    "              \n",
    "        contadorErro = contadorErro +1\n",
    "    else:\n",
    "        ArrayQuestoesCertas.append (\"qestão numero : \" + str(contador))\n",
    "        ArrayQuestoesCertas.append(val_dataframe.iloc[contador]['Question'])\n",
    "        ArrayQuestoesCertas.append(decodAns)\n",
    "        ArrayQuestoesCertas.append(val_dataframe.iloc[contador]['Answer'])\n",
    "       \n",
    "        contadorCerto = contadorCerto +1\n",
    "      \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb987d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VerifValList=[]\n",
    "print(\"certo : \" + str(contadorCerto))\n",
    "print(\"erro : \" + str(contadorErro))\n",
    "VerifValList.append(\"Acerto - \" + str(contadorCerto))\n",
    "VerifValList.append(\"Erro - \" + str(contadorErro ))\n",
    "tempo = (time.clock() - start_time, \"segundos\")\n",
    "print(tempo)\n",
    "VerifValList.append(\"tempo - \" + str(tempo ))\n",
    "GravarArquivo(VerifValList,'Verif_Val_resumo' )\n",
    "GravarArquivo(ArrayQuestoesCertas,'Verif_val_questoescertas' )\n",
    "GravarArquivo(ArrarQuestoesErradas,'Verif_val_questoeserradas' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'Percentage_'+ str(percentageData) +  '/ModelTreinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Final_Percentage_'+ str(percentageData) +  '/train_dataframe', \"wb\") as f:\n",
    "    pickle.dump(train_dataframe, f)\n",
    "with open('final_Percentage_'+ str(percentageData) +  '/encoder', \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "with open('final_Percentage_'+ str(percentageData) +  '/val_dataframe', \"wb\") as f:\n",
    "    pickle.dump(val_dataframe, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffccc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01e267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c34a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcfc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24861e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
